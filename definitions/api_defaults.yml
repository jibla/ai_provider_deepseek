chat:
  temperature: 0.7
  top_p: 1
  max_tokens: 1024
  presence_penalty: 0
  frequency_penalty: 0
  stop: []
  safe_prompt: true
  random_seed: null

models:
  deepseek-chat:
    name: DeepSeek Chat
    description: General purpose chat model
    default: true
    context_length: 32768
    capabilities:
      - chat
  deepseek-coder:
    name: DeepSeek Coder
    description: Code generation and analysis model
    default: false
    context_length: 32768
    capabilities:
      - chat
